---
title: "What is XAI"
date: 2025-02-25T19:34:24+02:00
draft: false
weight: 1
---

The sophistication of AI-powered systems have increased exponentially in the last decade. And yet, you can (almost) design and deployment whole AI models without any human intervention.

I came across the [experiment I shared on home page](/) when I was reading an article titled:

 [*Why Are We Using Black Box Models in AI When We Donâ€™t Need To? A Lesson From an Explainable AI Competition*](https://hdsr.mitpress.mit.edu/pub/f9kuryi8/release/8)

We are employing Machine Learning (ML) in more critical areas than ever. Hence it is natural to demand transparency in the decision-making process inside such models.

The article above argues that it makes more sense to shift our focus to **creating and working on** interpretable models rather than **explaining** black-box algorithms.

{{% notice style="accent" %}}
More accurate models does not have to mean less interpretability/transparency.
{{% /notice %}}

While I fully agree with the above statement, the truth is, convoluted models based on Deep Learning (DL) or Neural Networks (NN) methods have seen more success in applications (as compared to simpler models) [^cite]

And there is much work to be accomplished, before they enjoy more practical adoption.

[^cite]: *citation required*


ðŸ“Œ *This section is in progress*
