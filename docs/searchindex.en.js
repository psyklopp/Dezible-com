var relearn_searchindex = [
  {
    "breadcrumb": "Dezible",
    "content": "For this section, I will refer to an excellent article published in 2020. It has reviewed concepts related to explainability of AI methods, discussed some transparent models and built a taxonomy based on the reviewed literature.\n‚úíÔ∏è You can read the whole paper here Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI https://doi.org/10.1016/j.inffus.2019.12.012.",
    "description": "For this section, I will refer to an excellent article published in 2020. It has reviewed concepts related to explainability of AI methods, discussed some transparent models and built a taxonomy based on the reviewed literature.\n‚úíÔ∏è You can read the whole paper here Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI https://doi.org/10.1016/j.inffus.2019.12.012.",
    "tags": [],
    "title": "eXplainable AI",
    "uri": "/basics/"
  },
  {
    "breadcrumb": "Dezible¬†\u003e¬† eXplainable AI",
    "content": "The sophistication of AI-powered systems have increased exponentially in the last decade. And yet, you can (almost) design and deployment whole AI models without any human intervention.\nI came across the experiment I shared on home page when I was reading an article titled:\nWhy Are We Using Black Box Models in AI When We Don‚Äôt Need To? A Lesson From an Explainable AI Competition\nWe are employing Machine Learning (ML) in more critical areas than ever. Hence it is natural to demand transparency in the decision-making process inside such models.\nThe article above argues that it makes more sense to shift our focus to creating and working on interpretable models rather than explaining black-box algorithms.\nDetails More accurate models does not have to mean less interpretability/transparency.\nWhile I fully agree with the above statement, the truth is, convoluted models based on Deep Learning (DL) or Neural Networks (NN) methods have seen more success in applications (as compared to simpler models) 1\nAnd there is much work to be accomplished, before they enjoy more practical adoption.\nüìå This section is in progress\ncitation required¬†‚Ü©Ô∏é",
    "description": "The sophistication of AI-powered systems have increased exponentially in the last decade. And yet, you can (almost) design and deployment whole AI models without any human intervention.\nI came across the experiment I shared on home page when I was reading an article titled:\nWhy Are We Using Black Box Models in AI When We Don‚Äôt Need To? A Lesson From an Explainable AI Competition\nWe are employing Machine Learning (ML) in more critical areas than ever. Hence it is natural to demand transparency in the decision-making process inside such models.",
    "tags": [],
    "title": "What is XAI",
    "uri": "/basics/what-is-xai/"
  },
  {
    "breadcrumb": "Dezible",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Categories",
    "uri": "/categories/"
  },
  {
    "breadcrumb": "Dezible",
    "content": "And why do I want to talk about this topic?\nMy name is Aditya Bhardwaj and am currently a PhD candidate at University of Twente - you can find me here through LinkedIn profile\nI am deeply interested in following the progress in the area of XAI, specially in the methods of evaluating such XAI models.\nAnd as I am starting to go through academic research for my PhD, I realized that there is a lack of systemized knowledge on XAI. There might a lot of resources on this topic, but are present sparsely.\nDetails üí° The goal is to collect and organize the literature, with a focus on practical adoption of XAI and the challenges it faces. I will also focus on implementing such methods and sharing it as open-source code.",
    "description": "And why do I want to talk about this topic?\nMy name is Aditya Bhardwaj and am currently a PhD candidate at University of Twente - you can find me here through LinkedIn profile\nI am deeply interested in following the progress in the area of XAI, specially in the methods of evaluating such XAI models.\nAnd as I am starting to go through academic research for my PhD, I realized that there is a lack of systemized knowledge on XAI. There might a lot of resources on this topic, but are present sparsely.",
    "tags": [],
    "title": "Who am I?",
    "uri": "/goal/"
  },
  {
    "breadcrumb": "Dezible",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tags",
    "uri": "/tags/"
  }
]
