<!DOCTYPE html>
<html lang="en-us" dir="ltr" itemscope itemtype="http://schema.org/Article" data-r-output-format="print">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="height=device-height, width=device-width, initial-scale=1.0, minimum-scale=1.0">
    <meta name="generator" content="Hugo 0.144.1">
    <meta name="generator" content="Relearn 7.4.0">
    <meta name="description" content="Welcome to Dezible.
Read the interesting experiment below or check out the basics of XAI starting here.
Experiment In 2018, hundreds of top computer scientists, financial engineers, and executives - were asked to engage in a thought experiment where they had cancer and needed surgery to remove a tumor.
Two images were displayed on the screen.
First image Human surgeon, who could explain anything about the surgery, but had a 15% chance of causing death during the surgery.">
    <meta name="author" content="">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Dezible">
    <meta name="twitter:description" content="Welcome to Dezible.
Read the interesting experiment below or check out the basics of XAI starting here.
Experiment In 2018, hundreds of top computer scientists, financial engineers, and executives - were asked to engage in a thought experiment where they had cancer and needed surgery to remove a tumor.
Two images were displayed on the screen.
First image Human surgeon, who could explain anything about the surgery, but had a 15% chance of causing death during the surgery.">
    <meta property="og:url" content="https://dezible.com/">
    <meta property="og:site_name" content="Dezible">
    <meta property="og:title" content="Dezible">
    <meta property="og:description" content="Welcome to Dezible.
Read the interesting experiment below or check out the basics of XAI starting here.
Experiment In 2018, hundreds of top computer scientists, financial engineers, and executives - were asked to engage in a thought experiment where they had cancer and needed surgery to remove a tumor.
Two images were displayed on the screen.
First image Human surgeon, who could explain anything about the surgery, but had a 15% chance of causing death during the surgery.">
    <meta property="og:locale" content="en_us">
    <meta property="og:type" content="website">
    <meta itemprop="name" content="Dezible">
    <meta itemprop="description" content="Welcome to Dezible.
Read the interesting experiment below or check out the basics of XAI starting here.
Experiment In 2018, hundreds of top computer scientists, financial engineers, and executives - were asked to engage in a thought experiment where they had cancer and needed surgery to remove a tumor.
Two images were displayed on the screen.
First image Human surgeon, who could explain anything about the surgery, but had a 15% chance of causing death during the surgery.">
    <meta itemprop="datePublished" content="2025-02-25T19:34:24+02:00">
    <meta itemprop="dateModified" content="2025-02-25T19:34:24+02:00">
    <meta itemprop="wordCount" content="201">
    <title>Dezible</title>
    <link href="https://dezible.com/" rel="canonical" type="text/html" title="Dezible">
    <link href="/index.xml" rel="alternate" type="application/rss+xml" title="Dezible"><link rel="icon" href="https://raw.githubusercontent.com/psyklopp/Dezible-com/main/images/dezible_favicon.png" type="image/png">
    <link href="/css/fontawesome-all.min.css?1740567546" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="/css/fontawesome-all.min.css?1740567546" rel="stylesheet"></noscript>
    <link href="/css/auto-complete.css?1740567546" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="/css/auto-complete.css?1740567546" rel="stylesheet"></noscript>
    <link href="/css/perfect-scrollbar.min.css?1740567546" rel="stylesheet">
    <link href="/css/theme.min.css?1740567546" rel="stylesheet">
    <link href="/css/format-print.min.css?1740567546" rel="stylesheet" id="R-format-style">
    <script>
      window.relearn = window.relearn || {};
      window.relearn.relBasePath='.';
      window.relearn.relBaseUri='.';
      window.relearn.absBaseUri='https:\/\/dezible.com';
      window.relearn.min = `.min`;
      window.relearn.disableAnchorCopy=false;
      window.relearn.disableAnchorScrolling=false;
      window.relearn.enableBlockCodeWrap=true;
      window.relearn.disableInlineCopyToClipboard=true;
      // variant stuff
      window.relearn.themevariants = [ 'auto' ];
      window.relearn.customvariantname = "my-custom-variant";
      window.relearn.changeVariant = function(variant) {
        var oldVariant = document.documentElement.dataset.rThemeVariant;
        window.localStorage.setItem(window.relearn.absBaseUri + "/variant", variant);
        document.documentElement.dataset.rThemeVariant = variant;
        if (oldVariant != variant) {
          document.dispatchEvent( new CustomEvent('themeVariantLoaded', { detail: { variant, oldVariant } }) );
        }
      }
      window.relearn.markVariant = function() {
        var variant = window.localStorage.getItem(window.relearn.absBaseUri + "/variant");
        var select = document.querySelector("#R-select-variant");
        if (select) {
          select.value = variant;
        }
      }
      window.relearn.initVariant = function() {
        var variant = window.localStorage.getItem(window.relearn.absBaseUri + "/variant") ?? "";
        if( variant == window.relearn.customvariantname ){
        }else if( !variant || !window.relearn.themevariants.includes(variant) ){
          variant = window.relearn.themevariants[0];
          window.localStorage.setItem(window.relearn.absBaseUri + "/variant", variant);
        }
        document.documentElement.dataset.rThemeVariant = variant;
      }
      window.relearn.initVariant();
      window.relearn.markVariant();
      // translations
      window.T_Copy_to_clipboard = `Copy to clipboard`;
      window.T_Copied_to_clipboard = `Copied to clipboard!`;
      window.T_Copy_link_to_clipboard = `Copy link to clipboard`;
      window.T_Link_copied_to_clipboard = `Copied link to clipboard!`;
      window.T_Reset_view = `Reset view`;
      window.T_View_reset = `View reset!`;
      window.T_No_results_found = `No results found for "{0}"`;
      window.T_N_results_found = `{1} results found for "{0}"`;
    </script>

<style>
   :root {
    --MENU-WIDTH-S: 13.375rem;
    --MENU-WIDTH-M: 13.375rem;
    --MENU-WIDTH-L: 15.75rem;
    --MAIN-WIDTH-MAX: 80.25rem;
}
</style>

  </head>
  <body class="mobile-support print" data-url="/">
    <div id="R-body" class="default-animation">
      <div id="R-body-overlay"></div>
      <nav id="R-topbar">
        <div class="topbar-wrapper">
          <div class="topbar-sidebar-divider"></div>
          <div class="topbar-area topbar-area-start" data-area="start">
            <div class="topbar-button topbar-button-sidebar" data-content-empty="disable" data-width-s="show" data-width-m="hide" data-width-l="hide"><button class="topbar-control" onclick="toggleNav()" type="button" title="Menu (CTRL&#43;ALT&#43;n)"><i class="fa-fw fas fa-bars"></i></button>
            </div>
            <div class="topbar-button topbar-button-toc" data-content-empty="hide" data-width-s="show" data-width-m="show" data-width-l="show"><button class="topbar-control" onclick="toggleTopbarFlyout(this)" type="button" title="Table of Contents (CTRL&#43;ALT&#43;t)"><i class="fa-fw fas fa-list-alt"></i></button>
              <div class="topbar-content">
                <div class="topbar-content-wrapper">
<nav class="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#experiment">Experiment</a></li>
      </ul>
    </li>
  </ul>
</nav>
                </div>
              </div>
            </div>
          </div>
          <ol class="topbar-breadcrumbs breadcrumbs highlightable" itemscope itemtype="http://schema.org/BreadcrumbList">
            <li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><span itemprop="name">Dezible</span><meta itemprop="position" content="1"></li>
          </ol>
          <div class="topbar-area topbar-area-end" data-area="end">
            <div class="topbar-button topbar-button-print" data-content-empty="disable" data-width-s="area-more" data-width-m="show" data-width-l="show"><a class="topbar-control" href="/index.print.html" title="Print whole chapter (CTRL+ALT+p)"><i class="fa-fw fas fa-print"></i></a>
            </div>
            <div class="topbar-button topbar-button-prev" data-content-empty="disable" data-width-s="show" data-width-m="show" data-width-l="show"><span class="topbar-control"><i class="fa-fw fas fa-chevron-left"></i></span>
            </div>
            <div class="topbar-button topbar-button-next" data-content-empty="disable" data-width-s="show" data-width-m="show" data-width-l="show"><a class="topbar-control" href="/basics/" title="eXplainable AI (ðŸ¡’)"><i class="fa-fw fas fa-chevron-right"></i></a>
            </div>
            <div class="topbar-button topbar-button-more" data-content-empty="hide" data-width-s="show" data-width-m="show" data-width-l="show"><button class="topbar-control" onclick="toggleTopbarFlyout(this)" type="button" title="More"><i class="fa-fw fas fa-ellipsis-v"></i></button>
              <div class="topbar-content">
                <div class="topbar-content-wrapper">
                  <div class="topbar-area topbar-area-more" data-area="more">
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </nav>
      <div id="R-main-overlay"></div>
      <main id="R-body-inner" class="highlightable page" tabindex="-1">
        <div class="flex-block-wrapper">
          <section>
            <h1 class="a11y-only">Subsections of Dezible</h1>
<article class="default">
  <header class="headline">
  </header>

<h1 id="explainable-ai">eXplainable AI</h1>

<p>For this section, I will refer to an excellent article published in 2020. It has reviewed concepts related to explainability of AI methods, discussed some transparent models and built a taxonomy based on the reviewed literature.</p>

<details class=" box cstyle notices default expand" style=";--VARIABLE-BOX-color: green">
  <summary class="box-label">
    <i class="expander-icon fa-fw fas fa-chevron-right"></i> 
    &#x2712;&#xfe0f; You can read the whole paper here
  </summary>
  <div class="box-content">
<p><a href="https://www.sciencedirect.com/science/article/pii/S1566253519308103" rel="external" target="_blank">Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI</a>
<a href="https://doi.org/10.1016/j.inffus.2019.12.012" rel="external" target="_blank">https://doi.org/10.1016/j.inffus.2019.12.012</a>.</p>
  </div>
</details>

  <footer class="footline">
  </footer>
</article>
          <section>
            <h1 class="a11y-only">Subsections of eXplainable AI</h1>
<article class="default">
  <header class="headline">
  </header>

<h1 id="what-is-xai">What is XAI</h1>

<p>The sophistication of AI-powered systems have increased exponentially in the last decade. And yet, you can (almost) design and deployment whole AI models without any human intervention.</p>
<p>I came across the <a href="/">experiment I shared on home page</a> when I was reading an article titled:</p>
<p><a href="https://hdsr.mitpress.mit.edu/pub/f9kuryi8/release/8" rel="external" target="_blank"><em>Why Are We Using Black Box Models in AI When We Donâ€™t Need To? A Lesson From an Explainable AI Competition</em></a></p>
<p>We are employing Machine Learning (ML) in more critical areas than ever. Hence it is natural to demand transparency in the decision-making process inside such models.</p>
<p>The article above argues that it makes more sense to shift our focus to <strong>creating and working on</strong> interpretable models rather than <strong>explaining</strong> black-box algorithms.</p>

<details open class=" box cstyle notices accent">
  <summary class="box-label a11y-only" tabindex="-1">
    <span class="a11y-only">Details</span>
  </summary>
  <div class="box-content">
<p>More accurate models does not have to mean less interpretability/transparency.</p>
  </div>
</details>
<p>While I fully agree with the above statement, the truth is, convoluted models based on Deep Learning (DL) or Neural Networks (NN) methods have seen more success in applications (as compared to simpler models) <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>
<p>And there is much work to be accomplished, before they enjoy more practical adoption.</p>
<p>ðŸ“Œ <em>This section is in progress</em></p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p><em>citation required</em>&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>

  <footer class="footline">
  </footer>
</article>
          </section>
<article class="default">
  <header class="headline">
  </header>

<h1 id="who-am-i">Who am I?</h1>

<p>And why do I want to talk about this topic?</p>
<p>My name is Aditya Bhardwaj and am currently a PhD candidate at University of Twente - you can find me here through <a href="https://www.linkedin.com/in/ab4dev/" rel="external" target="_blank">LinkedIn profile</a></p>
<p>I am deeply interested in following the progress in the area of <strong>XAI</strong>, specially in the methods of evaluating such XAI models.</p>
<p>And as I am starting to go through academic research for my PhD, I realized that there is a lack of systemized knowledge on XAI. There might a lot of resources on this topic, but are present sparsely.</p>

<details open class=" box cstyle notices accent">
  <summary class="box-label a11y-only" tabindex="-1">
    <span class="a11y-only">Details</span>
  </summary>
  <div class="box-content">
<p>&#x1f4a1; The goal is to collect and organize the literature, with a focus on practical adoption of XAI and the challenges it faces. I will also focus on implementing such methods and sharing it as open-source code.</p>
  </div>
</details>

  <footer class="footline">
  </footer>
</article>
          </section>
        </div>
      </main>
    </div>
    <script src="/js/clipboard.min.js?1740567546" defer></script>
    <script src="/js/perfect-scrollbar.min.js?1740567546" defer></script>
    <script src="/js/theme.js?1740567546" defer></script>
  </body>
</html>
